{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/19 14:23:43 WARN Utils: Your hostname, devsidd resolves to a loopback address: 127.0.1.1; using 192.168.1.8 instead (on interface wlp2s0)\n",
      "24/03/19 14:23:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/19 14:23:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy Data Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleData = [\n",
    "    {\n",
    "        \"employee\": \"James\", \"department\": \"Sales\", \"state\": \"NY\", \"salary\": 90000, \"age\": 34, \"bonus\": 10000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Michael\", \"department\": \"Sales\", \"state\": \"NY\", \"salary\": 86000, \"age\": 56, \"bonus\": 20000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Robert\", \"department\": \"Sales\", \"state\": \"CA\", \"salary\": 81000, \"age\": 39, \"bonus\": 23000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Maria\", \"department\": \"Finance\", \"state\": \"CA\", \"salary\": 90000, \"age\": 24, \"bonus\": 23000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Raman\", \"department\": \"Finance\", \"state\": \"CA\", \"salary\": 99000, \"age\": 40, \"bonus\": 24000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Scott\", \"department\": \"Finance\", \"state\": \"NY\", \"salary\": 83000, \"age\": 36, \"bonus\": 19000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Jen\", \"department\": \"Finance\", \"state\": \"NY\", \"salary\": 79000, \"age\": 53, \"bonus\": 15000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Jeff\", \"department\": \"Marketing\", \"state\": \"CA\", \"salary\": 80000, \"age\": 25, \"bonus\": 18000\n",
    "    },\n",
    "    {\n",
    "        \"employee\": \"Kumar\", \"department\": \"Marketing\", \"state\": \"NY\", \"salary\": 91000, \"age\": 50, \"bonus\": 21000\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and Show Spark Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+--------+------+-----+\n",
      "|age|bonus|department|employee|salary|state|\n",
      "+---+-----+----------+--------+------+-----+\n",
      "| 34|10000|     Sales|   James| 90000|   NY|\n",
      "| 56|20000|     Sales| Michael| 86000|   NY|\n",
      "| 39|23000|     Sales|  Robert| 81000|   CA|\n",
      "| 24|23000|   Finance|   Maria| 90000|   CA|\n",
      "| 40|24000|   Finance|   Raman| 99000|   CA|\n",
      "| 36|19000|   Finance|   Scott| 83000|   NY|\n",
      "| 53|15000|   Finance|     Jen| 79000|   NY|\n",
      "| 25|18000| Marketing|    Jeff| 80000|   CA|\n",
      "| 50|21000| Marketing|   Kumar| 91000|   NY|\n",
      "+---+-----+----------+--------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# to read from a .csv file\n",
    "# df = spark.read.csv(\"<file_path>\")\n",
    "\n",
    "df = spark.createDataFrame(sampleData)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show as Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bonus</th>\n",
       "      <th>department</th>\n",
       "      <th>employee</th>\n",
       "      <th>salary</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>10000</td>\n",
       "      <td>Sales</td>\n",
       "      <td>James</td>\n",
       "      <td>90000</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>20000</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Michael</td>\n",
       "      <td>86000</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>23000</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Robert</td>\n",
       "      <td>81000</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>23000</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Maria</td>\n",
       "      <td>90000</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>24000</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Raman</td>\n",
       "      <td>99000</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  bonus department employee  salary state\n",
       "0   34  10000      Sales    James   90000    NY\n",
       "1   56  20000      Sales  Michael   86000    NY\n",
       "2   39  23000      Sales   Robert   81000    CA\n",
       "3   24  23000    Finance    Maria   90000    CA\n",
       "4   40  24000    Finance    Raman   99000    CA"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- employee: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumnRenamed(\"employee\", \"employee_name\")\n",
    "df.printSchema()\n",
    "\n",
    "# rename for all columns\n",
    "# df = df.toDF(*[\"age_xy\", \"bonus_xy\", \"department_xy\", \"employee_xy\", \"salary_xy\", \"state_xy\"])\n",
    "# df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---+-----+\n",
      "|employee_name|age|state|\n",
      "+-------------+---+-----+\n",
      "|        James| 34|   NY|\n",
      "|      Michael| 56|   NY|\n",
      "|       Robert| 39|   CA|\n",
      "|        Maria| 24|   CA|\n",
      "|        Raman| 40|   CA|\n",
      "|        Scott| 36|   NY|\n",
      "|          Jen| 53|   NY|\n",
      "|         Jeff| 25|   CA|\n",
      "|        Kumar| 50|   NY|\n",
      "+-------------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = df.select(\"employee_name\", \"age\", \"state\")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-------------+------+-----+\n",
      "|age|bonus|department|employee_name|salary|state|\n",
      "+---+-----+----------+-------------+------+-----+\n",
      "| 24|23000|   Finance|        Maria| 90000|   CA|\n",
      "| 25|18000| Marketing|         Jeff| 80000|   CA|\n",
      "| 34|10000|     Sales|        James| 90000|   NY|\n",
      "| 36|19000|   Finance|        Scott| 83000|   NY|\n",
      "| 39|23000|     Sales|       Robert| 81000|   CA|\n",
      "| 40|24000|   Finance|        Raman| 99000|   CA|\n",
      "| 50|21000| Marketing|        Kumar| 91000|   NY|\n",
      "| 53|15000|   Finance|          Jen| 79000|   NY|\n",
      "| 56|20000|     Sales|      Michael| 86000|   NY|\n",
      "+---+-----+----------+-------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## by default, in ascending order\n",
    "# df.sort('age').show()\n",
    "\n",
    "#OR\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.sort(F.asc('age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-------------+------+-----+\n",
      "|age|bonus|department|employee_name|salary|state|\n",
      "+---+-----+----------+-------------+------+-----+\n",
      "| 56|20000|     Sales|      Michael| 86000|   NY|\n",
      "| 53|15000|   Finance|          Jen| 79000|   NY|\n",
      "| 50|21000| Marketing|        Kumar| 91000|   NY|\n",
      "| 40|24000|   Finance|        Raman| 99000|   CA|\n",
      "| 39|23000|     Sales|       Robert| 81000|   CA|\n",
      "| 36|19000|   Finance|        Scott| 83000|   NY|\n",
      "| 34|10000|     Sales|        James| 90000|   NY|\n",
      "| 25|18000| Marketing|         Jeff| 80000|   CA|\n",
      "| 24|23000|   Finance|        Maria| 90000|   CA|\n",
      "+---+-----+----------+-------------+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## sort in descending order\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df.sort(F.desc('age')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new column using Spark UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-------------+------+-----+-----------+\n",
      "|age|bonus|department|employee_name|salary|state|salary_in_k|\n",
      "+---+-----+----------+-------------+------+-----+-----------+\n",
      "| 34|10000|     Sales|        James| 90000|   NY|       90.0|\n",
      "| 56|20000|     Sales|      Michael| 86000|   NY|       86.0|\n",
      "| 39|23000|     Sales|       Robert| 81000|   CA|       81.0|\n",
      "| 24|23000|   Finance|        Maria| 90000|   CA|       90.0|\n",
      "| 40|24000|   Finance|        Raman| 99000|   CA|       99.0|\n",
      "| 36|19000|   Finance|        Scott| 83000|   NY|       83.0|\n",
      "| 53|15000|   Finance|          Jen| 79000|   NY|       79.0|\n",
      "| 25|18000| Marketing|         Jeff| 80000|   CA|       80.0|\n",
      "| 50|21000| Marketing|        Kumar| 91000|   NY|       91.0|\n",
      "+---+-----+----------+-------------+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# normal python function\n",
    "def salary_in_k(x):\n",
    "    return x/1000\n",
    "\n",
    "# convert the above function to spark UDF and return type of function (Typecast)\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "salary_in_k_udf = F.udf(salary_in_k, T.DoubleType())\n",
    "\n",
    "# creating column\n",
    "df = df.withColumn('salary_in_k', salary_in_k_udf(F.col('salary')))\n",
    "\n",
    "df.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+-------------+------+-----+-----------+\n",
      "|age|bonus|department|employee_name|salary|state|salary_in_k|\n",
      "+---+-----+----------+-------------+------+-----+-----------+\n",
      "| 56|20000|     Sales|      Michael| 86000|   NY|       86.0|\n",
      "| 50|21000| Marketing|        Kumar| 91000|   NY|       91.0|\n",
      "+---+-----+----------+-------------+------+-----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((df.age >= 50) & (df.salary_in_k >= 80.0)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|department|sum(salary)|\n",
      "+----------+-----------+\n",
      "|     Sales|     257000|\n",
      "|   Finance|     351000|\n",
      "| Marketing|     171000|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy on single column with sum agg\n",
    "df.groupBy('department').sum('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----------+\n",
      "|department|sum(bonus)|sum(salary)|\n",
      "+----------+----------+-----------+\n",
      "|     Sales|     53000|     257000|\n",
      "|   Finance|     81000|     351000|\n",
      "| Marketing|     39000|     171000|\n",
      "+----------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# groupBy on multiple columns\n",
    "# df.groupBy('department', 'state').sum('salary', 'bonus').show()\n",
    "# df.groupBy('department').sum('salary', 'bonus').show()\n",
    "df.groupBy('department').agg({'salary': 'sum', 'bonus': 'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-----------------+----------+----------+\n",
      "|department|sum(salary)|      avg(salary)|min(bonus)|max(bonus)|\n",
      "+----------+-----------+-----------------+----------+----------+\n",
      "|     Sales|     257000|85666.66666666667|     10000|     23000|\n",
      "|   Finance|     351000|          87750.0|     15000|     24000|\n",
      "| Marketing|     171000|          85500.0|     18000|     21000|\n",
      "+----------+-----------+-----------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# running more aggregations at a time\n",
    "df.groupBy('department').agg(F.sum('salary'), F.avg('salary'),\n",
    "                            F.min('bonus'), F.max('bonus')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+---------+---------+\n",
      "|department|sum_salary|avg_salary|min_bonus|max_bonus|\n",
      "+----------+----------+----------+---------+---------+\n",
      "|   Finance|    351000|   87750.0|    15000|    24000|\n",
      "| Marketing|    171000|   85500.0|    18000|    21000|\n",
      "+----------+----------+----------+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# using filter and alias on the aggreated data\n",
    "df.groupBy('department').agg(F.sum('salary').alias('sum_salary'), \n",
    "                             F.avg('salary').alias('avg_salary'),\n",
    "                             F.min('bonus').alias('min_bonus'), \n",
    "                             F.max('bonus').alias('max_bonus')).where(\n",
    "                                                                F.col('min_bonus') >= 15000).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|department|unique_states|\n",
      "+----------+-------------+\n",
      "|     Sales|     [NY, CA]|\n",
      "|   Finance|     [CA, NY]|\n",
      "| Marketing|     [CA, NY]|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## collect aggregated list\n",
    "# df.groupBy('department').agg(F.collect_list('state')).alias('state_list').show()\n",
    "\n",
    "## Collect unique values for states per deparment\n",
    "df.groupBy('department').agg(F.collect_set('state').alias('unique_states')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark_testing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
